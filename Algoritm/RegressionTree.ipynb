{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_split(X, index, feature, split):\n",
    "    split_points = [[], []]\n",
    "    while index:\n",
    "        if X[index[0]][feature] < split:\n",
    "            split_points[0].append(index.pop(0))\n",
    "        else:\n",
    "            split_points[1].append(index.pop(0))\n",
    "    return split_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(self,score=None):\n",
    "        self.score = score\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.feature = None\n",
    "        self.split = None\n",
    "        \n",
    "class RegressionTree(object):\n",
    "    def __init__(self):\n",
    "        self.root = Node()\n",
    "        self.depth = 1\n",
    "        self._rules = None\n",
    "        \n",
    "    def getMSE(self,X,y,index,feature,split):\n",
    "        # left node, right node\n",
    "        split_sum = [0,0]\n",
    "        split_cnt = [0,0]\n",
    "        split_sqr_sum = [0,0]\n",
    "        \n",
    "        for i in index:\n",
    "            xi,yi = X[i][feature],y[i]\n",
    "            if xi < split:\n",
    "                split_cnt[0]+=1\n",
    "                split_sum[0]+=yi\n",
    "                split_sqr_sum[0]+=yi**2\n",
    "            else:\n",
    "                split_cnt[1]+=1\n",
    "                split_sum[1]+=yi\n",
    "                split_sqr_sum[1]+=yi**2\n",
    "        \n",
    "        avg = [split_sum[0]/split_cnt[0],split_sum[1]/split_cnt[1]]\n",
    "        mse = [(split_sqr_sum[0]**2+2*avg[0]*split_sum[0]+avg[0]**2)/split_cnt[0],\n",
    "              (split_sqr_sum[1]**2+2*avg[1]*split_sum[1]+avg[1]**2)/split_cnt[1]]\n",
    "        return sum(mse),split,avg\n",
    "    \n",
    "    def chooseSplit(self,X,y,index,feature):\n",
    "        unique = set([X[i][feature] for i in index])\n",
    "        if len(unique)==1:\n",
    "            return None\n",
    "        unique.remove(min(unique)) #prevent split_cnt is qeual to 0; if you didn't remove the least, you will get a divisionByZeroError\n",
    "        mse,split,avg = min(\n",
    "            [self.getMSE(X,y,index,feature,split)for split in unique],\n",
    "            key=lambda x:x[0])\n",
    "        return mse,feature,split,avg \n",
    "    \n",
    "    def chooseFeature(self,X,y,index):\n",
    "        number_of_feature = len(X[0])\n",
    "        split_points = map(lambda fs:self.chooseSplit(X,y,index,fs),range(number_of_feature))\n",
    "        split_points = filter(lambda sp:sp is not None, split_points)\n",
    "        min_mse,min_feature,min_split,min_avg = min(split_points,key=lambda x:x[0])\n",
    "        return min_mse,min_feature,min_split,min_avg\n",
    "    \n",
    "    def getRules(self):\n",
    "        queue = [[self.root,[]]]\n",
    "        self._rules=[]\n",
    "        while queue:\n",
    "            node,rule = queue.pop(0)\n",
    "            if not(node.left or node.right):\n",
    "                self._rules.append([node.score])\n",
    "            if node.left:\n",
    "                rule_left = rule[:]\n",
    "                rule_left.append([node.feature,-1,node.split])\n",
    "                queue.append([node.left,rule_left])\n",
    "            if node.right:\n",
    "                rule_right = rule[:]\n",
    "                rule_right.append([node.feature,1,node.split])\n",
    "                queue.append([node.right, rule_right])\n",
    "                \n",
    "    def fit(self,X,y,max_depth=6,min_samples_split=2):\n",
    "        self.root.score = sum(y)/len(y)\n",
    "        idx = list(range(len(y)))\n",
    "        queue = [(self.depth+1,self.root,idx)]\n",
    "        \n",
    "        while queue:\n",
    "            depth,node,index = queue.pop(0)\n",
    "            if depth>max_depth:\n",
    "                depth-=1\n",
    "                break\n",
    "                \n",
    "            if len(index)<min_samples_split or len(set(y[index]))==1:\n",
    "                continue\n",
    "            \n",
    "            split_points = self.chooseFeature(X,y,index)\n",
    "            if split_points is None:\n",
    "                continue\n",
    "                \n",
    "            _,feature,split,avg = split_points\n",
    "            node.feature = feature\n",
    "            node.split = split\n",
    "            node.left = Node(avg[0])\n",
    "            node.right = Node(avg[1])\n",
    "            \n",
    "            idx_split = list_split(X,index,feature,split)\n",
    "            queue.append((depth+1,node.left,idx_split[0]))\n",
    "            queue.append((depth+1,node.right,idx_split[1]))\n",
    "        self.depth = depth\n",
    "        self.getRules()\n",
    "        \n",
    "    @property\n",
    "    def rules(self):\n",
    "        for i,rule in enumerate(self._rules):\n",
    "            score = rule\n",
    "            print('Rule %d, y_hat %.4f'%(i,score))\n",
    "            \n",
    "    def _predict(self,Xi):\n",
    "        node = self.root\n",
    "        while node.left and node.right:\n",
    "            if Xi[node.feature] < node.split:\n",
    "                node = node.left\n",
    "            else:\n",
    "                node = node.right\n",
    "        return node.score\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return [self._predict(Xi) for Xi in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    m = len(y)\n",
    "    n = len(y_pred)\n",
    "    y_avg = sum(y) / len(y)\n",
    "    r2 = 1 - sum((yi - yi_pred) ** 2 for yi, yi_pred in zip(y, y_pred)) / sum((yi - y_avg) ** 2 for yi in y)\n",
    "    print(\"Test r2 is %.3f!\" % r2)\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test r2 is 0.033!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.03278921810057589"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "X,y = load_boston()['data'],load_boston()['target']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=123)\n",
    "RT = RegressionTree()\n",
    "RT.fit(X=X_train,y=y_train,max_depth=5)\n",
    "loss(RT,X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
